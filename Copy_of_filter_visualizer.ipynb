{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of filter_visualizer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcylmhlcy/pytorch1.0_MostUse/blob/master/Copy_of_filter_visualizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbRq1t7u4-IY",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing convolutional features using PyTorch\n",
        "\n",
        "## Please click \"OPEN IN PLAYGROUND\" and ensure that *runtime type* is set to *GPU* under menu *Runtime* before running the cells!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju9DqJJT47Is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fastai==0.7.0\n",
        "!pip install torchtext==0.2.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4zwSHx_8fLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall -y pillow==4.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c9oDLjV8ixP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pillow==4.1.1  \n",
        "# NO NEED TO RESTART RUNTIME AFTER INSTALLING PILLOW 4.1.1 EVEN THOUGH COLAB ASKS YOU TO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev0rGZwx4-tK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall -y torch==0.3.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8folMDk5J-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu90' if path.exists('/opt/bin/nvidia-smi') else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz3FvS3d5MU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(platform, accelerator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwD6cir-5Otl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRKRVHrK5Q5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.conv_learner import *\n",
        "from cv2 import resize\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsyIvkt75VKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SaveFeatures():\n",
        "    def __init__(self, module):\n",
        "        self.hook = module.register_forward_hook(self.hook_fn)\n",
        "    def hook_fn(self, module, input, output):\n",
        "        self.features = torch.tensor(output,requires_grad=True).cuda()\n",
        "    def close(self):\n",
        "        self.hook.remove()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrelS8_p5ZlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FilterVisualizer():\n",
        "    def __init__(self, size=56, upscaling_steps=12, upscaling_factor=1.2):\n",
        "        self.size, self.upscaling_steps, self.upscaling_factor = size, upscaling_steps, upscaling_factor\n",
        "        self.model = vgg16(pre=True).cuda().eval()\n",
        "        set_trainable(self.model, False)\n",
        "\n",
        "    def visualize(self, layer, filter, lr=0.1, opt_steps=20, blur=None):\n",
        "        sz = self.size\n",
        "        img = np.uint8(np.random.uniform(150, 180, (sz, sz, 3)))/255  # generate random image\n",
        "        activations = SaveFeatures(list(self.model.children())[layer])  # register hook\n",
        "\n",
        "        for _ in range(self.upscaling_steps):  # scale the image up upscaling_steps times\n",
        "            train_tfms, val_tfms = tfms_from_model(vgg16, sz)\n",
        "            img_var = V(val_tfms(img)[None], requires_grad=True)  # convert image to Variable that requires grad\n",
        "            optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6)\n",
        "            for n in range(opt_steps):  # optimize pixel values for opt_steps times\n",
        "                optimizer.zero_grad()\n",
        "                self.model(img_var)\n",
        "                loss = -activations.features[0, filter].mean()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            img = val_tfms.denorm(img_var.data.cpu().numpy()[0].transpose(1,2,0))\n",
        "            self.output = img\n",
        "            sz = int(self.upscaling_factor * sz)  # calculate new image size\n",
        "            img = cv2.resize(img, (sz, sz), interpolation = cv2.INTER_CUBIC)  # scale image up\n",
        "            if blur is not None: img = cv2.blur(img,(blur,blur))  # blur image to reduce high frequency patterns\n",
        "        self.save(layer, filter)\n",
        "        activations.close()\n",
        "        \n",
        "    def save(self, layer, filter):\n",
        "        plt.imsave(\"layer_\"+str(layer)+\"_filter_\"+str(filter)+\".jpg\", np.clip(self.output, 0, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_C_tidv5cea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer = 30\n",
        "filter = 180\n",
        "\n",
        "FV = FilterVisualizer(size=56, upscaling_steps=12, upscaling_factor=1.2)\n",
        "FV.visualize(layer, filter, blur=5)\n",
        "\n",
        "img = PIL.Image.open(\"layer_\"+str(layer)+\"_filter_\"+str(filter)+\".jpg\")\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.grid(None)\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYpRmWv76m_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}