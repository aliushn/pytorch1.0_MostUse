{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch1.0_.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcylmhlcy/pytorch1.0_MostUse/blob/master/pytorch1_0_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhBqyqLfY8H5",
        "colab_type": "code",
        "outputId": "ddb01ba9-ac21-4483-993c-f35389f32ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 25 12:15:31 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.56       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    31W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S0v_fR9bsSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import os\n",
        "import shutil\n",
        "import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toXI2Ka7b82j",
        "colab_type": "code",
        "outputId": "75b641fc-de5b-4efe-b27b-1df7877c4aeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(torch.__version__)               # PyTorch version\n",
        "print(torch.version.cuda)              # Corresponding CUDA version\n",
        "print(torch.backends.cudnn.version())  # Corresponding cuDNN version\n",
        "print(torch.cuda.get_device_name(0))   # GPU type"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.1.post2\n",
            "10.0.130\n",
            "7402\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdSIuAH2fcGi",
        "colab_type": "code",
        "outputId": "5d95f5e0-f4c0-46ff-b31a-a2d3e99623f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 判断是否有cuda支持\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da2EE483fsg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 设置为 cuDNN benchmark 模式\n",
        "\n",
        "# Benchmark 模式会提升计算速度，但是由于计算中有随机性，每次网络前馈结果略有差异。\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# 如果想要避免这种结果波动，设置\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Note:\n",
        "# 总的来说，大部分情况下，设置这个 benchmark 可以让内置的 cuDNN 的 auto-tuner 自动寻找最适合当前配置的高效算法，来达到优化运行效率的问题。\n",
        "# 一般来讲，应该遵循以下准则：\n",
        "# (1)如果网络的输入数据维度或类型上变化不大，设置  torch.backends.cudnn.benchmark = true  可以增加运行效率；\n",
        "# (2)如果网络的输入数据在每次 iteration 都变化的话，会导致 cnDNN 每次都会去寻找一遍最优配置，这样反而会降低运行效率。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hy2HkZZfhah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 清除 GPU 存储\n",
        "\n",
        "# 有时 Control-C 中止运行后 GPU 存储没有及时释放，需要手动清空。在 PyTorch 内部可以\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 或在命令行可以先使用 ps 找到程序的 PID，再使用 kill 结束该进程\n",
        "ps aux | grep pythonkill -9 [pid]\n",
        "\n",
        "# 或者直接重置没有被清空的 GPU\n",
        "nvidia-smi --gpu-reset -i [gpu_id]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-MhivXle-Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 在训练开始时，参数的初始化是随机的，为了让每次的结果一致，我们需要设置随机种子。\n",
        "\n",
        "# 固定GPU随机化种子\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "# 为CPU设置随机种子\n",
        "torch.manual_seed(args.seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFhKbASJg3wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensor--------------------------------------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiqSKstOhw3n",
        "colab_type": "code",
        "outputId": "ac59ba6c-c5ea-4b4a-82d4-53981d78e82f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "a = torch.Tensor([[1,2,3],[4,5,6]])\n",
        "print(a.type())\n",
        "print(a.size())\n",
        "print(a.dim())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.FloatTensor\n",
            "torch.Size([2, 3])\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBkEzHtgmO8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set default tensor type. Float in PyTorch is much faster than double.\n",
        "torch.set_default_tensor_type(torch.FloatTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCPX7IUwmOAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Type convertions.\n",
        "a = a.cuda() # convert Tensor a on CPU to Tensor a on GPU\n",
        "a = a.cpu() # convert Tensor a on GPU to Tensor a on CPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15tfdr6lnyV7",
        "colab_type": "code",
        "outputId": "d6eb5d96-d9ba-4371-e834-33146515443a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "b = a.float() # convert a to FloatTensor\n",
        "print(b.type())\n",
        "c = a.long() # convert a to LongTensor\n",
        "print(c.type())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.FloatTensor\n",
            "torch.LongTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztJLcwAXoHwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.Tensor -> np.ndarray.\n",
        "a = a.cuda()\n",
        "a = a.cpu().numpy()  # convert to numpy on CPU\n",
        "\n",
        "# np.ndarray -> torch.Tensor.\n",
        "a1 = np.array([[1,2,3],[4,5,6]], dtype=np.int64)\n",
        "b1 = torch.from_numpy(ndarray).float()\n",
        "c1 = torch.from_numpy(ndarray.copy()).float()  # If ndarray has negative stride"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "567skuYBo33M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.Tensor 与 PIL.Image 转换\n",
        "# PyTorch 中的张量默认采用 N×D×H×W 的顺序，并且数据范围在 [0, 1]，需要进行转置和规范化。\n",
        "\n",
        "# torch.Tensor -> PIL.Image.\n",
        "image = PIL.Image.fromarray(torch.clamp(tensor * 255, min=0, max=255).byte().permute(1, 2, 0).cpu().numpy())\n",
        "image = torchvision.transforms.functional.to_pil_image(tensor)  # Equivalently way\n",
        "\n",
        "# PIL.Image -> torch.Tensor.\n",
        "tensor = torch.from_numpy(np.asarray(PIL.Image.open(path))).permute(2, 0, 1).float() / 255\n",
        "tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path))  # Equivalently way"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqA0VgBh3I0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.ndarray 与 PIL.Image 转换\n",
        "\n",
        "# np.ndarray -> PIL.Image.\n",
        "image = PIL.Image.fromarray(ndarray.astypde(np.uint8))\n",
        "\n",
        "# PIL.Image -> np.ndarray.\n",
        "ndarray = np.asarray(PIL.Image.open(path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsQKUFj53XdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 从只包含一个元素的张量中提取值\n",
        "# 这在训练时统计 loss 的变化过程中特别有用。否则这将累积计算图，使 GPU 存储占用量越来越大。\n",
        "\n",
        "value = tensor.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AU7FWvI3fEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 张量形变\n",
        "# 张量形变常常需要用于将卷积层特征输入全连接层的情形。相比 torch.view，torch.reshape 可以自动处理输入张量不连续的情况。\n",
        "\n",
        "tensor = torch.reshape(tensor, shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bugXSOeg3ii5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # 打乱顺序\n",
        "\n",
        "tensor = tensor[torch.randperm(tensor.size(0))]  # Shuffle the first dimension"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4pbyOxj3oKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 水平翻转\n",
        "# PyTorch 不支持 tensor[::-1] 这样的负步长操作，水平翻转可以用张量索引实现。\n",
        "\n",
        "# Assume tensor has shape N*D*H*W.\n",
        "tensor = tensor[:, :, :, torch.arange(tensor.size(3) - 1, -1, -1).long()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB1sg--g3u3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 复制张量\n",
        "# 有三种复制的方式，对应不同的需求。\n",
        "\n",
        "# Operation                 |  New/Shared memory | Still in computation graph |\n",
        "tensor.clone()            # |        New         |          Yes               |\n",
        "tensor.detach()           # |      Shared        |          No                |\n",
        "tensor.detach.clone()()   # |        New         |          No                |"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZUTmSWq3tTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 拼接张量\n",
        "# 注意 torch.cat 和 torch.stack 的区别在于 torch.cat 沿着给定的维度拼接，而 torch.stack 会新增一维。\n",
        "# 例如当参数是 3 个 10×5 的张量，torch.cat 的结果是 30×5 的张量，而 torch.stack 的结果是 3×10×5 的张量。\n",
        "\n",
        "tensor = torch.cat(list_of_tensors, dim=0)\n",
        "tensor = torch.stack(list_of_tensors, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIEfFDIp4WE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将整数标记转换成独热（one-hot）编码\n",
        "# PyTorch 中的标记默认从 0 开始。\n",
        "\n",
        "N = tensor.size(0)\n",
        "one_hot = torch.zeros(N, num_classes).long()\n",
        "one_hot.scatter_(dim=1, index=torch.unsqueeze(tensor, dim=1), src=torch.ones(N, num_classes).long())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KBd3rTT4dVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 得到非零/零元素\n",
        "\n",
        "torch.nonzero(tensor)               # Index of non-zero elements\n",
        "torch.nonzero(tensor == 0)          # Index of zero elements\n",
        "torch.nonzero(tensor).size(0)       # Number of non-zero elements\n",
        "torch.nonzero(tensor == 0).size(0)  # Number of zero elements"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML9QbG3_4gRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 张量扩展\n",
        "\n",
        "# Expand tensor of shape 64*512 to shape 64*512*7*7.\n",
        "torch.reshape(tensor, (64, 512, 1, 1)).expand(64, 512, 7, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ljTGrNY4jPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 矩阵乘法\n",
        "\n",
        "# Matrix multiplication: (m*n) * (n*p) -> (m*p).\n",
        "result = torch.mm(tensor1, tensor2)\n",
        "\n",
        "# Batch matrix multiplication: (b*m*n) * (b*n*p) -> (b*m*p).\n",
        "result = torch.bmm(tensor1, tensor2)\n",
        "\n",
        "# Element-wise multiplication.\n",
        "result = tensor1 * tensor2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUzgFufG4m2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 计算两组数据之间的两两欧式距离\n",
        "\n",
        "# X1 is of shape m*d.\n",
        "X1 = torch.unsqueeze(X1, dim=1).expand(m, n, d)\n",
        "# X2 is of shape n*d.\n",
        "X2 = torch.unsqueeze(X2, dim=0).expand(m, n, d)\n",
        "# dist is of shape m*n, where dist[i][j] = sqrt(|X1[i, :] - X[j, :]|^2)\n",
        "dist = torch.sqrt(torch.sum((X1 - X2) ** 2, dim=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzqTARXi4rlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ----模型定义------------------------------------------------------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx6yJtN_4vrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}